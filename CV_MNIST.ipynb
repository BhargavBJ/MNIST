{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4bab276b4e714acc8d5d243c18af189d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_025751e0da5e4ed8b6a5b034f381540b",
              "IPY_MODEL_d9bc103f888d4c3f92775328c6b38472",
              "IPY_MODEL_c5150cc14b504a50888234a04b8d9042"
            ],
            "layout": "IPY_MODEL_4ed24c71cdc8486da7158ed09eab8737"
          }
        },
        "025751e0da5e4ed8b6a5b034f381540b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac9b86a464a042d8a1e610679d989f79",
            "placeholder": "​",
            "style": "IPY_MODEL_3860278a28b94405a013c6bb5e69d318",
            "value": "100%"
          }
        },
        "d9bc103f888d4c3f92775328c6b38472": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23627c8c87254cbf9dc83575f248d5a7",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a0db86fa7759470eb8e923186c18e324",
            "value": 5
          }
        },
        "c5150cc14b504a50888234a04b8d9042": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a29d604d807942b89b5b368428f750e6",
            "placeholder": "​",
            "style": "IPY_MODEL_167efdae82c442fa9457e0c140358e22",
            "value": " 5/5 [01:17&lt;00:00, 15.42s/it]"
          }
        },
        "4ed24c71cdc8486da7158ed09eab8737": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac9b86a464a042d8a1e610679d989f79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3860278a28b94405a013c6bb5e69d318": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "23627c8c87254cbf9dc83575f248d5a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0db86fa7759470eb8e923186c18e324": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a29d604d807942b89b5b368428f750e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "167efdae82c442fa9457e0c140358e22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch Computer vision"
      ],
      "metadata": {
        "id": "CZ3bL6PxAR5Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.Computer vision libraries\n",
        "\n",
        "* torchvision - base domain library\n",
        "* torchvision.datasets\n",
        "* torchvision.models - get pretrained models\n",
        "* torchvision.transformers\n",
        "* torch.utils.data.Dataset\n",
        "* torch.utils.data.DataLoader\n",
        "\n"
      ],
      "metadata": {
        "id": "beLtfhvXFqDH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "#Torch Vison\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "print(torch.__version__)\n",
        "print(torchvision.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IwK49ZfFYDVX",
        "outputId": "fd97eefc-a4fc-4031-e4d2-c257f0e8b9bd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.0+cu124\n",
            "0.21.0+cu124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1.Getting a Dataset\n",
        ">  MNIST\n"
      ],
      "metadata": {
        "id": "8yeb9bC_ZU7P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Setup training data\n",
        "train_data = datasets.MNIST(\n",
        "    root = 'data',\n",
        "    train =True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        "    target_transform=None\n",
        ")\n",
        "test_data =  datasets.MNIST(\n",
        "    root = 'data',\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        "    target_transform=None\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2PDsJj0Ytf9",
        "outputId": "412c85e4-6f12-4126-9dee-86126c1e5dd1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 17.6MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 489kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.47MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 7.01MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data), len(test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ouvM5rRvbAFc",
        "outputId": "062ca39c-b8d6-437b-bc38-bf460df661e4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 10000)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image, label = train_data[0]\n",
        "image, label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWfGNGyybN86",
        "outputId": "785f668e-42a9-443c-ae55-d60031746e26"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0706, 0.0706, 0.0706,\n",
              "           0.4941, 0.5333, 0.6863, 0.1020, 0.6510, 1.0000, 0.9686, 0.4980,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.1176, 0.1412, 0.3686, 0.6039, 0.6667, 0.9922, 0.9922, 0.9922,\n",
              "           0.9922, 0.9922, 0.8824, 0.6745, 0.9922, 0.9490, 0.7647, 0.2510,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922,\n",
              "           0.9333, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
              "           0.9922, 0.9843, 0.3647, 0.3216, 0.3216, 0.2196, 0.1529, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706,\n",
              "           0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765, 0.7137,\n",
              "           0.9686, 0.9451, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.3137, 0.6118, 0.4196, 0.9922, 0.9922, 0.8039, 0.0431, 0.0000,\n",
              "           0.1686, 0.6039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0549, 0.0039, 0.6039, 0.9922, 0.3529, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.5451, 0.9922, 0.7451, 0.0078, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0431, 0.7451, 0.9922, 0.2745, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.1373, 0.9451, 0.8824, 0.6275,\n",
              "           0.4235, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 0.9412, 0.9922,\n",
              "           0.9922, 0.4667, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1765, 0.7294,\n",
              "           0.9922, 0.9922, 0.5882, 0.1059, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627,\n",
              "           0.3647, 0.9882, 0.9922, 0.7333, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.9765, 0.9922, 0.9765, 0.2510, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1804, 0.5098,\n",
              "           0.7176, 0.9922, 0.9922, 0.8118, 0.0078, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.1529, 0.5804, 0.8980, 0.9922,\n",
              "           0.9922, 0.9922, 0.9804, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0941, 0.4471, 0.8667, 0.9922, 0.9922, 0.9922,\n",
              "           0.9922, 0.7882, 0.3059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0902, 0.2588, 0.8353, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765,\n",
              "           0.3176, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.6706,\n",
              "           0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.7647, 0.3137, 0.0353,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.2157, 0.6745, 0.8863, 0.9922,\n",
              "           0.9922, 0.9922, 0.9922, 0.9569, 0.5216, 0.0431, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.5333, 0.9922, 0.9922, 0.9922,\n",
              "           0.8314, 0.5294, 0.5176, 0.0627, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000]]]),\n",
              " 5)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = train_data.classes\n",
        "class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fq5QWz7LbbS-",
        "outputId": "8513ed2f-b955-4604-ad23-2337756c3dbb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['0 - zero',\n",
              " '1 - one',\n",
              " '2 - two',\n",
              " '3 - three',\n",
              " '4 - four',\n",
              " '5 - five',\n",
              " '6 - six',\n",
              " '7 - seven',\n",
              " '8 - eight',\n",
              " '9 - nine']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_to_idx = train_data.class_to_idx\n",
        "class_to_idx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uT4ac1nKbnKD",
        "outputId": "408cd42c-d972-47dd-b2f5-1a3e3e43dc71"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'0 - zero': 0,\n",
              " '1 - one': 1,\n",
              " '2 - two': 2,\n",
              " '3 - three': 3,\n",
              " '4 - four': 4,\n",
              " '5 - five': 5,\n",
              " '6 - six': 6,\n",
              " '7 - seven': 7,\n",
              " '8 - eight': 8,\n",
              " '9 - nine': 9}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.targets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QailtZ2mbsIf",
        "outputId": "1a808642-eec9-4324-9be9-5a52f27cd45e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5, 0, 4,  ..., 5, 6, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Image shape={image.shape}, Labels ={label}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULP2jifKbuuu",
        "outputId": "bc68381c-6550-4d78-e76f-19289144c014"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image shape=torch.Size([1, 28, 28]), Labels =5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualize\n",
        "import matplotlib.pyplot as plt\n",
        "image ,label = train_data[0]\n",
        "plt.title(class_names[label])\n",
        "plt.imshow(image.squeeze(), cmap='hot')\n",
        "plt.axis(False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "kKBfhdenbyJN",
        "outputId": "c01c2b57-d546-4f5d-f48a-a72dd78d73e7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(np.float64(-0.5), np.float64(27.5), np.float64(27.5), np.float64(-0.5))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot more images\n",
        "torch.manual_seed(42)\n",
        "fig = plt.figure(figsize=(9,9))\n",
        "rows, cols =4, 4\n",
        "for i in range(1, rows*cols+1):\n",
        "  rand = torch.randint(0,len(train_data), size=[1]).item()\n",
        "  img, label = train_data[rand]\n",
        "  fig.add_subplot(rows,cols, i)\n",
        "  plt.imshow(img.squeeze(), cmap='hot')\n",
        "  plt.title(class_names[label])\n",
        "  plt.axis(False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 752
        },
        "id": "hbvlVEo7cZnK",
        "outputId": "7b456e4b-e7b6-448b-9c0a-75f74d25bf2e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 900x900 with 16 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.Prepare Data Loader"
      ],
      "metadata": {
        "id": "0vqLNtKr35zy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data,test_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QAduJssd-Nl",
        "outputId": "f655c029-98cc-4308-ddbc-3ff9ea3ca23f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Dataset MNIST\n",
              "     Number of datapoints: 60000\n",
              "     Root location: data\n",
              "     Split: Train\n",
              "     StandardTransform\n",
              " Transform: ToTensor(),\n",
              " Dataset MNIST\n",
              "     Number of datapoints: 10000\n",
              "     Root location: data\n",
              "     Split: Test\n",
              "     StandardTransform\n",
              " Transform: ToTensor())"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "m_QfTrR44R5v",
        "outputId": "d94fac2a-e2a4-46f6-a0ad-7a32b0222bf2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "#Set up batch size hyperparameter\n",
        "batch = 32\n",
        "\n",
        "train_dataloader = DataLoader(dataset=train_data,\n",
        "                              batch_size=batch,\n",
        "                            shuffle=True)\n",
        "\n",
        "test_dataloader = DataLoader(dataset= test_data,\n",
        "                             batch_size=batch,\n",
        "                             shuffle=False)\n",
        "\n",
        "train_dataloader,test_dataloader"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPSaIjGd4zIx",
        "outputId": "6735bab4-49f4-4c80-8bbe-0199b2e10440"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<torch.utils.data.dataloader.DataLoader at 0x7e0caaba1210>,\n",
              " <torch.utils.data.dataloader.DataLoader at 0x7e0da5ead850>)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Check what is creaked\n",
        "print(f'DataLoaders: {train_dataloader, test_dataloader}')\n",
        "print(f'Lenght of train: {len(train_dataloader)} batches of {batch}')\n",
        "print(f'Lenght of train: {len(test_dataloader)} batches of {batch}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5oK1vQH51uq",
        "outputId": "0988d860-15ea-4499-dd46-a8d5a5745980"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataLoaders: (<torch.utils.data.dataloader.DataLoader object at 0x7e0caaba1210>, <torch.utils.data.dataloader.DataLoader object at 0x7e0da5ead850>)\n",
            "Lenght of train: 1875 batches of 32\n",
            "Lenght of train: 313 batches of 32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_features_batch, train_labels_batch = next(iter(train_dataloader))\n",
        "train_features_batch.shape, train_labels_batch.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7lMxzpf6mab",
        "outputId": "1af76907-b262-4a19-924b-12b0125708eb"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 1, 28, 28]), torch.Size([32]))"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualizing a single peice of a dataloader\n",
        "torch.manual_seed(42)\n",
        "random_idx = torch.randint(0,len(train_features_batch), size=[1]).item()\n",
        "img, label = train_features_batch[random_idx], train_labels_batch[random_idx]\n",
        "plt.imshow(img.squeeze(), cmap='hot')\n",
        "plt.title(class_names[label])\n",
        "plt.axis(False)\n",
        "print(f'Image size: {img.shape}')\n",
        "print(f'label: {label}, label size: {label.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "Hap2qUEM6Cny",
        "outputId": "7bc8b6ae-064e-4cc8-84e0-d84dbdf7fafc"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image size: torch.Size([1, 28, 28])\n",
            "label: 9, label size: torch.Size([])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGbCAYAAAAr/4yjAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAADFdJREFUeJzt3F2IX3V+x/Hv35mAcfJgMgR8SmwMGYWSoo20ZaPmonEMWGy0bfCixERBgxRMbWrVi+aBDJYmai+KS12KSoWu4OouWLyoItUFreJDMdpirKZNJSwYIyZRoyanN9tPyZrInONM/mN8vSAXGf4fzi+g8+Y48ddrmqYpAKiq0/p9AACmDlEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUYBx6PV6tXnz5n4fAyadKDDlvPrqq7Vy5cqaNWtWzZw5s0ZHR+uNN97o97Hge6Hn7iOmktdee62WLVtW8+fPr1tuuaWOHj1aDzzwQH300Uf18ssv14UXXtiXc33++ec1ODhYg4ODfXk+nCyiwJRy9dVX14svvli7du2q4eHhqqrau3dvjYyM1OjoaP3kJz/p8wnh1OY/HzGlvPDCC7VixYoEoarq7LPPruXLl9dTTz1VBw8enLBnrV27tmbMmFEffPBBrVq1qmbMmFHz5s2rjRs31pEjR4757K/+TGHz5s3V6/Xq3XffrbVr19aZZ55Zs2fPrnXr1tWnn376tWc9+uijtXTp0po+fXrNnTu3rr/++tqzZ8+E/VlgoogCU8rhw4dr+vTpX/v6GWecUV988UXt3LlzQp935MiRuuqqq2p4eLh27NhRy5cvr3vvvbcefPDBce1Xr15dBw4cqHvuuadWr15dDz/8cG3ZsuWYz4yNjdWaNWtq8eLFdd9999WGDRvq2WefrSuuuKI+/vjjCf3zwLfWwBSyZMmSZmRkpPnqq6/ytcOHDzcLFixoqqp5/PHHJ+xZN9xwQ1NVzdatW4/5+iWXXNIsXbr0mK9VVbNp06b8ftOmTU1VNTfeeOMxn7v22mub4eHh/H737t3NwMBAMzY2dszn3nzzzWZwcPBrX4d+86bAlHLrrbfWO++8UzfddFO9/fbbtXPnzlqzZk3t3bu3qqo+++yzCX/m+vXrj/n95ZdfXu+9917n7b59++qTTz6pqqonnniijh49WqtXr64PP/wwv84666xavHhxPffccxPzh4AJ4q9SMKWsX7++9uzZU9u3b69HHnmkqqouvfTSuuOOO2psbKxmzJhxwu3BgweP+ZnDwMBAzZs37xufd/rpp3/tM3PmzKn9+/eP67wLFiz42raqav/+/TVr1qzatWtXNU1TixcvPu5+2rRp43oOnCyiwJQzNjZWGzdurLfeeqtmz55dS5YsqbvvvruqqkZGRk6427FjxzH/Pf/888+v3bt3f+OzBgYGvtVZT7RvfvmX+o4ePVq9Xq+efvrp4372myIH/SAKTElz5sypyy67LL9/5pln6rzzzquLLrrohJs1a9YcszneD6xPtkWLFlXTNLVw4cJvDBpMFX6mwJT32GOP1SuvvFIbNmyo00478T+yF1xwQa1YsSK/li1bdhJPeXzXXXddDQwM1JYtW/L28H+apql9+/b16WRwfN4UmFKef/752rp1a42Ojtbw8HC99NJL9dBDD9XKlSvrtttu6/fxWlu0aFFt27at7rrrrtq9e3etWrWqZs6cWe+//349+eSTdfPNN9fGjRv7fUwIUWBKOffcc2tgYKC2b99eBw4cqIULF9a2bdvq9ttv/85eMXHnnXfWyMhI3X///fmZx/z582t0dLSuueaaPp8OjuWaCwDCzxQACFEAIEQBgBAFAEIUAAhRACDG/Re/h3q9yTwHAJPs0Dj+DwRvCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEIP9PgBMhtM7bH7UYXPdX3cY/flvdRhVVf1rx11bN7af/OlDrSdDf9P+MUw+bwoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIA4UI8prx1HTZ/25zTYfVfHTZd/E/H3dL2kytfaz159Zn2j/n79hOmKG8KAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIRbUulkZofNf3Z81lCzp8PqrA6bf2k/uXJF68nGDreQVlX9sNsMWvGmAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABAuxKOTf++wGWq+nPBznNg1rRdX9Z5uvfl56wVMbd4UAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAMKFeNTcDps57034Mb7Br7deXN57p/XmtdYLOPV4UwAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIF+JRf9xltPDLiT7Gid3mcjs4WbwpABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABC9pmma8XxwqNeb7LPQJ2d22Hzwbx1Gv9H1ZtV3O2yuaj/57f9uv7my/aSOdNhUVc3rsFnXfvLS3Pab320/oQ8OjePbvTcFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgHAhHp38XofNYz/s+LD1OzqMbuv4MGrdtNaToYcn/hhMPBfiAdCKKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgDhQjymvHM6bH6/w2bHjA6jgQ6bH3XYVFX90ZcdRv/RevHPvSWtN6taL+gHF+IB0IooABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCAOFCPPgW/rDD5pHmrzo+7c/aT34wrfVk6MX2j+G7wYV4ALQiCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAEAM9vsA8F32yDVdVh0utquqqp2tF3/icjta8qYAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQLglFX7px11GP/tyoo9xYn95SevJQ5NwDE5t3hQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAotc0TTOeDw71epN9FuirQ693GF08rn99fsWiDpuq3+m913rzZqcncao6NI5v994UAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAGKw3weAyfBPXUYXH+gw+nnrxV90uNiuyuV2nBzeFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQCi1zRNM54PDvV6k30WOK6fdthc2XRZDbef/OblrSdDr7d/DEyEQ+P4du9NAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBciMdJ82sdd281czusftF+8g/TWk+G1rR/DPSLC/EAaEUUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAGKw3wfg++Otc7ouO9x4Wu2vL73YjafgTQGA/ycKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQLgQj04Odhl98HrHpz3bevF3vX9svdnVegGnHm8KAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCAOFCPGpFh02v+XGH1S86bKpq8crWk9u7PQm+97wpABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQL8U4xP+iw+VnTZfUH7SfbpnV4TtXQu51mQAfeFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFACIXtM0zXg+ONTrTfZZAJhEh8bx7d6bAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgDRa5qm6fchAJgavCkAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQ/wuZW6iAgFyMVgAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3.Model building\n",
        "\n",
        "beginning from model 0"
      ],
      "metadata": {
        "id": "pXoo7k_Lq2Me"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "flatten_model = nn.Flatten()\n",
        "\n",
        "x=train_features_batch[0]\n",
        "\n",
        "output = flatten_model(x)\n",
        "print(output.shape)"
      ],
      "metadata": {
        "id": "SjD6h6pH6TF1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "676e9911-0f27-4a3c-d982-e0ea613bea2a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 784])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "class FashionMNISTModelV0(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv_block1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Dropout(0.25)\n",
        "        )\n",
        "        self.conv_block2 = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Dropout(0.25)\n",
        "        )\n",
        "        self.conv_block3 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Dropout(0.25)\n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(128 * 3 * 3, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(128, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_block1(x)\n",
        "        x = self.conv_block2(x)\n",
        "        x = self.conv_block3(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "XUCbUzInrT4m"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(model_0.parameters()).device\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2hvkJA-aU7m",
        "outputId": "7ae6270b-5076-4c0d-d247-24714b00c181"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "model_0 = FashionMNISTModelV0()\n",
        "model_0.to(device)\n",
        "model_0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_oUZ0yVMrlAA",
        "outputId": "8f7a93f4-ff09-4dd6-e7ac-0f9d0a9216c7"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FashionMNISTModelV0(\n",
              "  (conv_block1): Sequential(\n",
              "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU()\n",
              "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (7): Dropout(p=0.25, inplace=False)\n",
              "  )\n",
              "  (conv_block2): Sequential(\n",
              "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU()\n",
              "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (7): Dropout(p=0.25, inplace=False)\n",
              "  )\n",
              "  (conv_block3): Sequential(\n",
              "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (4): Dropout(p=0.25, inplace=False)\n",
              "  )\n",
              "  (fc): Sequential(\n",
              "    (0): Linear(in_features=1152, out_features=256, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=256, out_features=128, bias=True)\n",
              "    (4): ReLU()\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Linear(in_features=128, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dummy_x = torch.rand([1, 1, 28, 28]).to(device)\n",
        "model_0(dummy_x)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-EEobDgs6in",
        "outputId": "d2317b78-b852-4706-8536-cf5ad8ace2f8"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0156, -0.1717, -0.1181,  0.1326,  0.1069, -0.0156, -0.0713,  0.2862,\n",
              "          0.0692,  0.0099]], device='cuda:0', grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_0.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2LcWfxqtGCb",
        "outputId": "bd7662d2-74e1-41a5-dcdb-5f691f791a5c"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('conv_block1.0.weight',\n",
              "              tensor([[[[ 0.2548,  0.2767, -0.0781],\n",
              "                        [ 0.3062, -0.0730,  0.0673],\n",
              "                        [-0.1623,  0.1958,  0.2938]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.2445,  0.2897,  0.0624],\n",
              "                        [ 0.2463,  0.0451,  0.1607],\n",
              "                        [-0.0471,  0.2570,  0.0493]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.1556,  0.0850, -0.1536],\n",
              "                        [-0.0391, -0.1354,  0.2211],\n",
              "                        [-0.2631, -0.1537, -0.0941]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.2004,  0.0315, -0.3292],\n",
              "                        [ 0.3010, -0.2832,  0.2573],\n",
              "                        [ 0.0555, -0.1082,  0.2060]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 0.0520,  0.2693,  0.0364],\n",
              "                        [-0.1051,  0.0896, -0.0904],\n",
              "                        [ 0.1403,  0.2976,  0.1927]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.1457,  0.1924,  0.0596],\n",
              "                        [ 0.1693, -0.2032, -0.3300],\n",
              "                        [-0.1288, -0.2557,  0.2735]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 0.0960,  0.1381,  0.1054],\n",
              "                        [-0.0058,  0.2609, -0.2368],\n",
              "                        [ 0.0210, -0.2275,  0.1028]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.1148,  0.1021, -0.0694],\n",
              "                        [ 0.2765, -0.1976, -0.1988],\n",
              "                        [-0.1988,  0.2998,  0.1111]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 0.3208, -0.2751, -0.3306],\n",
              "                        [-0.2608, -0.2242,  0.1350],\n",
              "                        [ 0.1194,  0.2770, -0.1721]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.2272,  0.1769, -0.1347],\n",
              "                        [ 0.2023, -0.0791,  0.1907],\n",
              "                        [-0.2590, -0.1682,  0.1016]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 0.0705, -0.0850,  0.1987],\n",
              "                        [ 0.2266, -0.2417, -0.1780],\n",
              "                        [ 0.3052, -0.1125, -0.1182]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.3225, -0.1909,  0.0833],\n",
              "                        [-0.0440, -0.2420,  0.0078],\n",
              "                        [-0.2277, -0.2828, -0.1836]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.2917, -0.2122,  0.3332],\n",
              "                        [ 0.0630,  0.1027, -0.3109],\n",
              "                        [-0.2189, -0.1110,  0.0521]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.2933, -0.1436, -0.1996],\n",
              "                        [ 0.0009, -0.1240, -0.0231],\n",
              "                        [-0.2259, -0.2288, -0.1945]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.1141, -0.2631,  0.2795],\n",
              "                        [-0.0662,  0.2868,  0.1039],\n",
              "                        [-0.2823,  0.2307, -0.0917]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.1278, -0.2767, -0.3314],\n",
              "                        [ 0.0954, -0.0728,  0.1298],\n",
              "                        [-0.2736,  0.2475, -0.2447]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.0576,  0.0696,  0.1721],\n",
              "                        [ 0.2691,  0.3037, -0.2643],\n",
              "                        [ 0.0839, -0.1434, -0.0365]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.2495,  0.3036, -0.2447],\n",
              "                        [ 0.1782,  0.1171,  0.1083],\n",
              "                        [-0.1802,  0.3030,  0.0733]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 0.0429, -0.2938,  0.1399],\n",
              "                        [-0.0500, -0.1527,  0.2863],\n",
              "                        [ 0.0743, -0.1844, -0.1687]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.0159,  0.1861, -0.0852],\n",
              "                        [-0.1902, -0.1141, -0.2490],\n",
              "                        [ 0.1189,  0.2580, -0.3138]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 0.0774,  0.1722,  0.0604],\n",
              "                        [-0.1187,  0.1740,  0.1752],\n",
              "                        [ 0.1246, -0.0586, -0.0883]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 0.0357, -0.0589, -0.0993],\n",
              "                        [ 0.2131,  0.2865, -0.0330],\n",
              "                        [-0.0746,  0.0049, -0.0199]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 0.0801,  0.0934, -0.3028],\n",
              "                        [-0.1230,  0.2807,  0.1299],\n",
              "                        [-0.0166, -0.2010, -0.2039]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.2986, -0.1087,  0.1126],\n",
              "                        [ 0.2125,  0.1539, -0.2946],\n",
              "                        [-0.2005, -0.0526,  0.3224]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 0.0482, -0.0863,  0.1379],\n",
              "                        [-0.1270, -0.2158,  0.2433],\n",
              "                        [-0.1516, -0.0668, -0.3316]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 0.2231,  0.2525,  0.1215],\n",
              "                        [-0.2324, -0.3290, -0.2707],\n",
              "                        [ 0.2486,  0.1600,  0.2805]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 0.1746,  0.0844, -0.0033],\n",
              "                        [-0.2535, -0.2856, -0.3118],\n",
              "                        [ 0.1365, -0.1637, -0.0671]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.1918, -0.0607, -0.2346],\n",
              "                        [-0.2178,  0.1106, -0.0991],\n",
              "                        [ 0.2058, -0.1069, -0.2445]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.0588, -0.1616, -0.1020],\n",
              "                        [-0.3173,  0.1865, -0.2321],\n",
              "                        [ 0.1675,  0.1513,  0.2381]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.2557,  0.2397, -0.1576],\n",
              "                        [ 0.1237,  0.3130, -0.0470],\n",
              "                        [-0.0026, -0.0767, -0.2783]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 0.1600, -0.3309,  0.2069],\n",
              "                        [ 0.2494,  0.3152, -0.0786],\n",
              "                        [-0.2739,  0.0749,  0.1841]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.3318, -0.0757, -0.1998],\n",
              "                        [-0.0292, -0.1641, -0.1363],\n",
              "                        [-0.1058, -0.3168,  0.2735]]]], device='cuda:0')),\n",
              "             ('conv_block1.0.bias',\n",
              "              tensor([ 0.2794, -0.0523, -0.0380, -0.1360, -0.3010, -0.3244,  0.1239, -0.1830,\n",
              "                      -0.2143, -0.0260, -0.1110, -0.1078,  0.0107, -0.0707, -0.1148, -0.1596,\n",
              "                      -0.2713,  0.2795, -0.1334,  0.0883, -0.1157,  0.0271,  0.3108,  0.1536,\n",
              "                      -0.2889,  0.1323,  0.3164,  0.0877,  0.2235,  0.3286, -0.0511,  0.0692],\n",
              "                     device='cuda:0')),\n",
              "             ('conv_block1.1.weight',\n",
              "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "                     device='cuda:0')),\n",
              "             ('conv_block1.1.bias',\n",
              "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "                      0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
              "             ('conv_block1.1.running_mean',\n",
              "              tensor([ 0.4169,  0.0518, -0.1255, -0.1449, -0.1889, -0.3712,  0.1562, -0.1817,\n",
              "                      -0.2665, -0.0510, -0.1027, -0.2861, -0.0648, -0.2527, -0.1042, -0.2682,\n",
              "                      -0.2209,  0.3315, -0.1723,  0.0368, -0.0498,  0.0594,  0.2773,  0.1341,\n",
              "                      -0.3587,  0.1900,  0.2288, -0.0190,  0.2072,  0.3106,  0.0134, -0.0688],\n",
              "                     device='cuda:0')),\n",
              "             ('conv_block1.1.running_var',\n",
              "              tensor([0.0726, 0.0516, 0.0324, 0.0096, 0.0512, 0.0158, 0.0098, 0.0036, 0.0248,\n",
              "                      0.0068, 0.0128, 0.1262, 0.0262, 0.1219, 0.0150, 0.0466, 0.0215, 0.0209,\n",
              "                      0.0111, 0.0179, 0.0212, 0.0092, 0.0084, 0.0077, 0.0268, 0.0156, 0.0460,\n",
              "                      0.0438, 0.0160, 0.0096, 0.0201, 0.0841], device='cuda:0')),\n",
              "             ('conv_block1.1.num_batches_tracked',\n",
              "              tensor(1875, device='cuda:0')),\n",
              "             ('conv_block1.3.weight',\n",
              "              tensor([[[[-0.0410, -0.0121,  0.0436],\n",
              "                        [ 0.0302, -0.0373, -0.0473],\n",
              "                        [-0.0403, -0.0582, -0.0455]],\n",
              "              \n",
              "                       [[-0.0146,  0.0398,  0.0099],\n",
              "                        [-0.0448, -0.0473,  0.0293],\n",
              "                        [-0.0438, -0.0073,  0.0283]],\n",
              "              \n",
              "                       [[-0.0273, -0.0064, -0.0051],\n",
              "                        [-0.0139, -0.0299, -0.0525],\n",
              "                        [-0.0476, -0.0316,  0.0569]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-0.0513,  0.0072,  0.0521],\n",
              "                        [ 0.0101,  0.0160, -0.0343],\n",
              "                        [-0.0008,  0.0032,  0.0145]],\n",
              "              \n",
              "                       [[ 0.0229,  0.0512, -0.0450],\n",
              "                        [ 0.0018, -0.0294, -0.0466],\n",
              "                        [-0.0047, -0.0519,  0.0411]],\n",
              "              \n",
              "                       [[ 0.0068, -0.0318,  0.0308],\n",
              "                        [-0.0558, -0.0228, -0.0115],\n",
              "                        [-0.0501, -0.0375, -0.0096]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 0.0447,  0.0569,  0.0375],\n",
              "                        [-0.0352, -0.0386,  0.0514],\n",
              "                        [ 0.0208,  0.0016,  0.0080]],\n",
              "              \n",
              "                       [[-0.0474, -0.0197,  0.0567],\n",
              "                        [-0.0145, -0.0030, -0.0489],\n",
              "                        [-0.0330, -0.0012, -0.0366]],\n",
              "              \n",
              "                       [[-0.0073,  0.0240, -0.0576],\n",
              "                        [ 0.0175, -0.0390, -0.0288],\n",
              "                        [ 0.0226,  0.0469, -0.0161]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-0.0496, -0.0061,  0.0565],\n",
              "                        [ 0.0150,  0.0050, -0.0122],\n",
              "                        [-0.0206,  0.0351,  0.0036]],\n",
              "              \n",
              "                       [[ 0.0383, -0.0104,  0.0257],\n",
              "                        [ 0.0243,  0.0094,  0.0370],\n",
              "                        [ 0.0369,  0.0546,  0.0453]],\n",
              "              \n",
              "                       [[-0.0151, -0.0499,  0.0108],\n",
              "                        [-0.0005, -0.0154, -0.0099],\n",
              "                        [ 0.0028,  0.0430,  0.0184]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.0209, -0.0242, -0.0146],\n",
              "                        [-0.0228,  0.0530,  0.0312],\n",
              "                        [ 0.0532,  0.0002,  0.0119]],\n",
              "              \n",
              "                       [[ 0.0204, -0.0558,  0.0053],\n",
              "                        [-0.0039, -0.0330, -0.0457],\n",
              "                        [ 0.0522,  0.0479,  0.0273]],\n",
              "              \n",
              "                       [[ 0.0562, -0.0239, -0.0102],\n",
              "                        [ 0.0223, -0.0097, -0.0116],\n",
              "                        [-0.0487,  0.0158, -0.0356]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[ 0.0404, -0.0459,  0.0538],\n",
              "                        [ 0.0046,  0.0283,  0.0458],\n",
              "                        [ 0.0502, -0.0459,  0.0516]],\n",
              "              \n",
              "                       [[-0.0400,  0.0044, -0.0412],\n",
              "                        [-0.0129, -0.0027, -0.0070],\n",
              "                        [-0.0093,  0.0046,  0.0581]],\n",
              "              \n",
              "                       [[ 0.0342,  0.0330,  0.0236],\n",
              "                        [ 0.0456, -0.0027,  0.0047],\n",
              "                        [ 0.0121, -0.0514, -0.0475]]],\n",
              "              \n",
              "              \n",
              "                      ...,\n",
              "              \n",
              "              \n",
              "                      [[[-0.0045, -0.0051, -0.0571],\n",
              "                        [ 0.0105, -0.0468,  0.0053],\n",
              "                        [-0.0140,  0.0375, -0.0236]],\n",
              "              \n",
              "                       [[ 0.0419, -0.0140, -0.0114],\n",
              "                        [-0.0536,  0.0512,  0.0051],\n",
              "                        [-0.0531,  0.0033,  0.0241]],\n",
              "              \n",
              "                       [[-0.0125,  0.0481,  0.0288],\n",
              "                        [-0.0076,  0.0589,  0.0416],\n",
              "                        [-0.0072, -0.0051,  0.0181]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[ 0.0396,  0.0161,  0.0500],\n",
              "                        [-0.0573, -0.0144, -0.0380],\n",
              "                        [-0.0451, -0.0350,  0.0186]],\n",
              "              \n",
              "                       [[ 0.0392,  0.0266, -0.0202],\n",
              "                        [ 0.0260,  0.0580,  0.0029],\n",
              "                        [-0.0212, -0.0465,  0.0417]],\n",
              "              \n",
              "                       [[-0.0135, -0.0462,  0.0341],\n",
              "                        [ 0.0117, -0.0238, -0.0580],\n",
              "                        [ 0.0074, -0.0175, -0.0102]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.0197,  0.0485,  0.0313],\n",
              "                        [ 0.0467,  0.0222,  0.0168],\n",
              "                        [ 0.0582, -0.0002,  0.0339]],\n",
              "              \n",
              "                       [[ 0.0240, -0.0564,  0.0400],\n",
              "                        [-0.0058, -0.0398,  0.0397],\n",
              "                        [-0.0477,  0.0276, -0.0485]],\n",
              "              \n",
              "                       [[-0.0169, -0.0553,  0.0421],\n",
              "                        [ 0.0146,  0.0481,  0.0180],\n",
              "                        [-0.0292,  0.0089,  0.0399]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[ 0.0260,  0.0569, -0.0316],\n",
              "                        [-0.0047, -0.0049,  0.0480],\n",
              "                        [ 0.0556,  0.0149, -0.0476]],\n",
              "              \n",
              "                       [[-0.0427,  0.0108, -0.0519],\n",
              "                        [-0.0206, -0.0442,  0.0302],\n",
              "                        [-0.0081, -0.0461,  0.0385]],\n",
              "              \n",
              "                       [[-0.0522, -0.0058,  0.0567],\n",
              "                        [ 0.0295, -0.0511,  0.0064],\n",
              "                        [-0.0088,  0.0262,  0.0544]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 0.0502, -0.0056,  0.0271],\n",
              "                        [-0.0579,  0.0464,  0.0313],\n",
              "                        [-0.0414, -0.0170, -0.0229]],\n",
              "              \n",
              "                       [[-0.0345,  0.0243, -0.0172],\n",
              "                        [ 0.0245, -0.0179,  0.0458],\n",
              "                        [-0.0232, -0.0102, -0.0183]],\n",
              "              \n",
              "                       [[ 0.0027, -0.0217, -0.0414],\n",
              "                        [-0.0560,  0.0367,  0.0082],\n",
              "                        [-0.0379,  0.0305,  0.0062]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[ 0.0513,  0.0242,  0.0503],\n",
              "                        [ 0.0044, -0.0447, -0.0377],\n",
              "                        [ 0.0532,  0.0528,  0.0178]],\n",
              "              \n",
              "                       [[-0.0421,  0.0431,  0.0244],\n",
              "                        [-0.0465,  0.0171,  0.0568],\n",
              "                        [-0.0389,  0.0045,  0.0168]],\n",
              "              \n",
              "                       [[-0.0212,  0.0388,  0.0524],\n",
              "                        [ 0.0574, -0.0527,  0.0033],\n",
              "                        [ 0.0481,  0.0502, -0.0152]]]], device='cuda:0')),\n",
              "             ('conv_block1.3.bias',\n",
              "              tensor([ 0.0390,  0.0440, -0.0037,  0.0404,  0.0339, -0.0088, -0.0246, -0.0313,\n",
              "                      -0.0475, -0.0352,  0.0154,  0.0210, -0.0169, -0.0049,  0.0408,  0.0087,\n",
              "                      -0.0409,  0.0499,  0.0356,  0.0068,  0.0281, -0.0498,  0.0346,  0.0143,\n",
              "                      -0.0052, -0.0189,  0.0476,  0.0127, -0.0329,  0.0265,  0.0104, -0.0207],\n",
              "                     device='cuda:0')),\n",
              "             ('conv_block1.4.weight',\n",
              "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "                     device='cuda:0')),\n",
              "             ('conv_block1.4.bias',\n",
              "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "                      0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
              "             ('conv_block1.4.running_mean',\n",
              "              tensor([-0.2397,  0.1271, -0.1086,  0.0675,  0.3194, -0.2923, -0.1703,  0.0731,\n",
              "                      -0.0499,  0.0332, -0.0386, -0.1476,  0.2056, -0.0059, -0.3689,  0.2566,\n",
              "                       0.4048, -0.0256,  0.2439, -0.0561, -0.2959,  0.2123,  0.2867, -0.2701,\n",
              "                       0.2539, -0.3271, -0.1979,  0.2342,  0.0374, -0.0813,  0.3437,  0.0254],\n",
              "                     device='cuda:0')),\n",
              "             ('conv_block1.4.running_var',\n",
              "              tensor([0.0672, 0.0994, 0.0855, 0.0661, 0.2263, 0.3384, 0.0429, 0.0321, 0.1241,\n",
              "                      0.0836, 0.0455, 0.0931, 0.0699, 0.0521, 0.0946, 0.1686, 0.0885, 0.0983,\n",
              "                      0.1931, 0.0548, 0.1485, 0.0520, 0.1459, 0.3279, 0.1213, 0.2520, 0.1193,\n",
              "                      0.0945, 0.0457, 0.1828, 0.1690, 0.0478], device='cuda:0')),\n",
              "             ('conv_block1.4.num_batches_tracked',\n",
              "              tensor(1875, device='cuda:0')),\n",
              "             ('conv_block2.0.weight',\n",
              "              tensor([[[[ 0.0416,  0.0587, -0.0026],\n",
              "                        [-0.0243, -0.0316, -0.0308],\n",
              "                        [ 0.0302,  0.0370, -0.0357]],\n",
              "              \n",
              "                       [[ 0.0326,  0.0023, -0.0021],\n",
              "                        [-0.0187, -0.0543, -0.0505],\n",
              "                        [ 0.0432, -0.0097, -0.0026]],\n",
              "              \n",
              "                       [[-0.0355, -0.0108, -0.0230],\n",
              "                        [ 0.0053, -0.0562,  0.0057],\n",
              "                        [-0.0522, -0.0419, -0.0013]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-0.0384,  0.0143, -0.0071],\n",
              "                        [ 0.0503,  0.0028, -0.0291],\n",
              "                        [ 0.0472,  0.0018, -0.0099]],\n",
              "              \n",
              "                       [[ 0.0281,  0.0568,  0.0269],\n",
              "                        [ 0.0017,  0.0483, -0.0258],\n",
              "                        [ 0.0521, -0.0336,  0.0011]],\n",
              "              \n",
              "                       [[ 0.0536,  0.0235, -0.0123],\n",
              "                        [ 0.0363,  0.0348, -0.0531],\n",
              "                        [-0.0066, -0.0464, -0.0127]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.0071, -0.0236, -0.0215],\n",
              "                        [ 0.0319, -0.0017, -0.0586],\n",
              "                        [ 0.0101, -0.0579, -0.0404]],\n",
              "              \n",
              "                       [[ 0.0360,  0.0450, -0.0209],\n",
              "                        [-0.0358,  0.0267, -0.0563],\n",
              "                        [ 0.0364,  0.0406,  0.0249]],\n",
              "              \n",
              "                       [[ 0.0180,  0.0122, -0.0452],\n",
              "                        [-0.0236,  0.0380,  0.0496],\n",
              "                        [ 0.0016,  0.0151, -0.0559]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-0.0551,  0.0392,  0.0410],\n",
              "                        [ 0.0370,  0.0249, -0.0357],\n",
              "                        [-0.0253,  0.0126,  0.0232]],\n",
              "              \n",
              "                       [[ 0.0517,  0.0026,  0.0243],\n",
              "                        [-0.0445, -0.0120,  0.0350],\n",
              "                        [ 0.0048,  0.0466, -0.0473]],\n",
              "              \n",
              "                       [[-0.0393,  0.0185, -0.0025],\n",
              "                        [-0.0503,  0.0251,  0.0024],\n",
              "                        [ 0.0142,  0.0129, -0.0406]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.0395, -0.0471,  0.0428],\n",
              "                        [-0.0323,  0.0530, -0.0188],\n",
              "                        [ 0.0130,  0.0563, -0.0316]],\n",
              "              \n",
              "                       [[-0.0559,  0.0085, -0.0425],\n",
              "                        [ 0.0325,  0.0234,  0.0427],\n",
              "                        [-0.0061, -0.0385, -0.0543]],\n",
              "              \n",
              "                       [[-0.0381,  0.0525, -0.0126],\n",
              "                        [-0.0011, -0.0125, -0.0301],\n",
              "                        [ 0.0482, -0.0153, -0.0286]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-0.0554,  0.0265,  0.0278],\n",
              "                        [-0.0573,  0.0257,  0.0075],\n",
              "                        [-0.0368, -0.0270,  0.0579]],\n",
              "              \n",
              "                       [[-0.0307,  0.0516,  0.0119],\n",
              "                        [ 0.0270, -0.0297,  0.0192],\n",
              "                        [ 0.0127,  0.0470, -0.0583]],\n",
              "              \n",
              "                       [[-0.0214,  0.0015, -0.0423],\n",
              "                        [ 0.0100,  0.0380,  0.0355],\n",
              "                        [-0.0304,  0.0238, -0.0429]]],\n",
              "              \n",
              "              \n",
              "                      ...,\n",
              "              \n",
              "              \n",
              "                      [[[-0.0550,  0.0110,  0.0254],\n",
              "                        [-0.0173, -0.0378,  0.0468],\n",
              "                        [ 0.0146,  0.0283,  0.0568]],\n",
              "              \n",
              "                       [[-0.0459,  0.0410, -0.0222],\n",
              "                        [ 0.0220,  0.0383,  0.0429],\n",
              "                        [ 0.0195,  0.0071,  0.0016]],\n",
              "              \n",
              "                       [[-0.0155,  0.0311,  0.0563],\n",
              "                        [ 0.0008, -0.0507, -0.0127],\n",
              "                        [-0.0166,  0.0301, -0.0464]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[ 0.0147, -0.0520,  0.0004],\n",
              "                        [-0.0381,  0.0217, -0.0298],\n",
              "                        [-0.0020,  0.0430, -0.0434]],\n",
              "              \n",
              "                       [[ 0.0410,  0.0367,  0.0036],\n",
              "                        [ 0.0488, -0.0394, -0.0460],\n",
              "                        [-0.0213,  0.0495, -0.0341]],\n",
              "              \n",
              "                       [[ 0.0214, -0.0413,  0.0040],\n",
              "                        [ 0.0501,  0.0420,  0.0266],\n",
              "                        [-0.0249,  0.0287,  0.0501]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.0536,  0.0150, -0.0300],\n",
              "                        [ 0.0286, -0.0036, -0.0129],\n",
              "                        [-0.0413, -0.0406,  0.0075]],\n",
              "              \n",
              "                       [[ 0.0179, -0.0016,  0.0474],\n",
              "                        [-0.0042, -0.0412,  0.0207],\n",
              "                        [-0.0394,  0.0497,  0.0085]],\n",
              "              \n",
              "                       [[ 0.0019,  0.0208,  0.0290],\n",
              "                        [-0.0438, -0.0235, -0.0196],\n",
              "                        [-0.0012,  0.0273, -0.0279]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[ 0.0358, -0.0285,  0.0040],\n",
              "                        [-0.0439, -0.0377,  0.0047],\n",
              "                        [ 0.0282,  0.0519, -0.0585]],\n",
              "              \n",
              "                       [[ 0.0351,  0.0209,  0.0557],\n",
              "                        [-0.0013, -0.0033, -0.0579],\n",
              "                        [ 0.0332, -0.0079, -0.0172]],\n",
              "              \n",
              "                       [[-0.0129, -0.0398, -0.0177],\n",
              "                        [ 0.0165,  0.0372, -0.0416],\n",
              "                        [-0.0548,  0.0096,  0.0488]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 0.0002, -0.0096, -0.0322],\n",
              "                        [-0.0076, -0.0333,  0.0314],\n",
              "                        [ 0.0019, -0.0048, -0.0261]],\n",
              "              \n",
              "                       [[ 0.0319, -0.0516,  0.0491],\n",
              "                        [-0.0253, -0.0327,  0.0011],\n",
              "                        [ 0.0581, -0.0246,  0.0368]],\n",
              "              \n",
              "                       [[-0.0060, -0.0462, -0.0024],\n",
              "                        [ 0.0181,  0.0379, -0.0119],\n",
              "                        [-0.0331, -0.0174,  0.0326]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-0.0058,  0.0194,  0.0516],\n",
              "                        [ 0.0048,  0.0460, -0.0213],\n",
              "                        [-0.0313,  0.0397,  0.0483]],\n",
              "              \n",
              "                       [[ 0.0441,  0.0076, -0.0032],\n",
              "                        [-0.0002, -0.0026,  0.0088],\n",
              "                        [ 0.0208,  0.0363,  0.0154]],\n",
              "              \n",
              "                       [[ 0.0547, -0.0098,  0.0135],\n",
              "                        [-0.0033, -0.0419, -0.0469],\n",
              "                        [-0.0032, -0.0472, -0.0494]]]], device='cuda:0')),\n",
              "             ('conv_block2.0.bias',\n",
              "              tensor([ 2.7439e-02,  2.6059e-02,  4.7903e-02,  4.3318e-02,  4.7762e-02,\n",
              "                      -3.4623e-02,  1.8482e-02,  1.5072e-02, -1.8113e-02, -5.3588e-02,\n",
              "                       7.6998e-03, -1.7439e-02, -9.2018e-03,  1.0776e-02,  2.1327e-02,\n",
              "                       4.3692e-05, -3.7908e-02,  3.3791e-02, -2.4475e-02, -4.5380e-02,\n",
              "                       3.0359e-02, -3.5979e-04, -1.1213e-02,  1.7652e-02, -4.5837e-02,\n",
              "                       1.8938e-02,  3.1438e-02, -3.1396e-02,  5.4347e-02,  1.5134e-02,\n",
              "                      -7.2964e-03,  4.3955e-02,  2.7358e-02,  2.4565e-03,  5.2082e-02,\n",
              "                       3.2143e-02, -4.2484e-02, -2.3791e-02, -3.4054e-02,  4.0865e-02,\n",
              "                       3.2544e-02, -3.6242e-02,  1.6048e-02, -2.9390e-02,  3.2974e-02,\n",
              "                       8.0685e-03, -1.1816e-03, -2.7120e-02,  4.6150e-02, -7.0787e-03,\n",
              "                      -4.5672e-02, -7.5106e-03, -2.4440e-02,  5.6677e-02, -5.8252e-02,\n",
              "                       1.7713e-02, -2.3607e-03, -5.3358e-02,  1.5620e-03, -2.3689e-02,\n",
              "                      -2.8003e-02, -4.6709e-02,  1.0350e-02,  4.0604e-02], device='cuda:0')),\n",
              "             ('conv_block2.1.weight',\n",
              "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')),\n",
              "             ('conv_block2.1.bias',\n",
              "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "                     device='cuda:0')),\n",
              "             ('conv_block2.1.running_mean',\n",
              "              tensor([ 0.1301, -0.2404, -0.5063, -0.0960, -0.0427, -0.1196, -0.0167, -0.2219,\n",
              "                      -0.0547, -0.2299, -0.2264,  0.0953, -0.1330, -0.3564,  0.2642,  0.4902,\n",
              "                       0.1637, -0.5132, -0.1772, -0.2922,  0.2219, -0.4737,  0.6935, -0.1152,\n",
              "                      -0.2481,  0.0407,  0.5850, -0.3621,  0.0579,  0.0725, -0.6067, -0.3638,\n",
              "                      -0.2939, -0.1780, -0.3142, -0.1321, -0.1715, -0.1925,  0.1999,  0.2463,\n",
              "                      -0.0996,  0.1750,  0.5816,  0.2965,  0.5806, -0.1045,  0.0729, -0.3719,\n",
              "                      -0.1172, -0.3197,  0.1688,  0.4325,  0.3783,  0.2157,  0.0151,  0.3406,\n",
              "                       0.2865, -0.1458, -0.2035,  0.0859,  0.3759,  0.6337, -0.4261,  0.4029],\n",
              "                     device='cuda:0')),\n",
              "             ('conv_block2.1.running_var',\n",
              "              tensor([0.2836, 0.3391, 0.4031, 0.2449, 0.2383, 0.3659, 0.3698, 0.5022, 0.3449,\n",
              "                      0.3366, 0.3321, 0.2371, 0.2696, 0.3494, 0.6322, 0.4964, 0.3316, 0.6704,\n",
              "                      0.3941, 0.5501, 0.3901, 0.4649, 0.7029, 0.4292, 0.2683, 0.2477, 0.5596,\n",
              "                      0.3282, 0.2199, 0.2476, 0.7513, 0.7277, 0.4058, 0.3586, 0.3159, 0.3347,\n",
              "                      0.2864, 0.3806, 0.3039, 0.2512, 0.2367, 0.3732, 0.5127, 0.4364, 0.5599,\n",
              "                      0.2312, 0.2592, 0.2876, 0.1996, 0.5094, 0.2973, 0.4571, 0.5196, 0.2224,\n",
              "                      0.2283, 0.5202, 0.2401, 0.3046, 0.3889, 0.3614, 0.3310, 0.6820, 0.3771,\n",
              "                      0.2775], device='cuda:0')),\n",
              "             ('conv_block2.1.num_batches_tracked',\n",
              "              tensor(1875, device='cuda:0')),\n",
              "             ('conv_block2.3.weight',\n",
              "              tensor([[[[-0.0105,  0.0282,  0.0143],\n",
              "                        [-0.0276, -0.0384, -0.0123],\n",
              "                        [ 0.0168, -0.0377,  0.0367]],\n",
              "              \n",
              "                       [[-0.0403,  0.0172,  0.0205],\n",
              "                        [-0.0302,  0.0302,  0.0023],\n",
              "                        [-0.0413,  0.0126,  0.0099]],\n",
              "              \n",
              "                       [[-0.0318, -0.0178, -0.0021],\n",
              "                        [-0.0163,  0.0289, -0.0080],\n",
              "                        [ 0.0052,  0.0093, -0.0008]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-0.0330, -0.0069, -0.0416],\n",
              "                        [-0.0135,  0.0137, -0.0327],\n",
              "                        [ 0.0157,  0.0415,  0.0106]],\n",
              "              \n",
              "                       [[-0.0285, -0.0144, -0.0108],\n",
              "                        [-0.0037, -0.0303, -0.0109],\n",
              "                        [ 0.0124, -0.0383, -0.0306]],\n",
              "              \n",
              "                       [[ 0.0197, -0.0091, -0.0219],\n",
              "                        [ 0.0003,  0.0224,  0.0211],\n",
              "                        [-0.0067, -0.0053,  0.0199]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 0.0396, -0.0206,  0.0138],\n",
              "                        [-0.0080,  0.0295,  0.0218],\n",
              "                        [-0.0344, -0.0129,  0.0123]],\n",
              "              \n",
              "                       [[-0.0304, -0.0371,  0.0051],\n",
              "                        [-0.0270,  0.0018, -0.0312],\n",
              "                        [-0.0410,  0.0412,  0.0307]],\n",
              "              \n",
              "                       [[-0.0403,  0.0395, -0.0125],\n",
              "                        [ 0.0201,  0.0304,  0.0049],\n",
              "                        [-0.0239,  0.0305,  0.0059]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-0.0081,  0.0223,  0.0058],\n",
              "                        [ 0.0091,  0.0324, -0.0219],\n",
              "                        [-0.0133,  0.0012,  0.0220]],\n",
              "              \n",
              "                       [[ 0.0146, -0.0234,  0.0348],\n",
              "                        [-0.0087,  0.0341, -0.0179],\n",
              "                        [ 0.0240, -0.0092,  0.0054]],\n",
              "              \n",
              "                       [[ 0.0346,  0.0077,  0.0048],\n",
              "                        [-0.0126,  0.0172, -0.0086],\n",
              "                        [-0.0013,  0.0044,  0.0284]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 0.0063, -0.0257, -0.0060],\n",
              "                        [ 0.0134, -0.0372, -0.0201],\n",
              "                        [-0.0104, -0.0131, -0.0116]],\n",
              "              \n",
              "                       [[-0.0047,  0.0115, -0.0226],\n",
              "                        [-0.0250,  0.0341,  0.0099],\n",
              "                        [-0.0195,  0.0013, -0.0339]],\n",
              "              \n",
              "                       [[ 0.0061, -0.0364, -0.0353],\n",
              "                        [ 0.0371, -0.0297, -0.0313],\n",
              "                        [ 0.0116, -0.0071,  0.0149]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[ 0.0304, -0.0035, -0.0413],\n",
              "                        [-0.0018, -0.0033,  0.0222],\n",
              "                        [ 0.0329,  0.0387, -0.0098]],\n",
              "              \n",
              "                       [[-0.0177, -0.0099, -0.0134],\n",
              "                        [-0.0315,  0.0131,  0.0350],\n",
              "                        [-0.0238,  0.0025,  0.0234]],\n",
              "              \n",
              "                       [[ 0.0382,  0.0227, -0.0142],\n",
              "                        [-0.0057, -0.0158, -0.0148],\n",
              "                        [-0.0273,  0.0052,  0.0237]]],\n",
              "              \n",
              "              \n",
              "                      ...,\n",
              "              \n",
              "              \n",
              "                      [[[ 0.0103, -0.0345,  0.0327],\n",
              "                        [-0.0241,  0.0118, -0.0025],\n",
              "                        [-0.0097,  0.0283,  0.0096]],\n",
              "              \n",
              "                       [[ 0.0403,  0.0169, -0.0163],\n",
              "                        [ 0.0408,  0.0205, -0.0108],\n",
              "                        [-0.0263, -0.0319,  0.0335]],\n",
              "              \n",
              "                       [[-0.0244,  0.0032,  0.0039],\n",
              "                        [ 0.0081,  0.0192, -0.0397],\n",
              "                        [-0.0243, -0.0049, -0.0091]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[ 0.0165, -0.0184, -0.0057],\n",
              "                        [ 0.0198, -0.0109, -0.0036],\n",
              "                        [ 0.0342,  0.0118, -0.0334]],\n",
              "              \n",
              "                       [[-0.0312,  0.0196, -0.0328],\n",
              "                        [ 0.0219,  0.0092, -0.0087],\n",
              "                        [ 0.0071, -0.0337,  0.0308]],\n",
              "              \n",
              "                       [[-0.0176,  0.0267,  0.0293],\n",
              "                        [-0.0123, -0.0370, -0.0159],\n",
              "                        [ 0.0166, -0.0285,  0.0377]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.0282, -0.0066, -0.0329],\n",
              "                        [ 0.0017, -0.0217, -0.0029],\n",
              "                        [ 0.0286,  0.0405,  0.0048]],\n",
              "              \n",
              "                       [[ 0.0096,  0.0007,  0.0400],\n",
              "                        [ 0.0138, -0.0173,  0.0218],\n",
              "                        [-0.0084,  0.0378, -0.0226]],\n",
              "              \n",
              "                       [[-0.0187,  0.0200, -0.0274],\n",
              "                        [-0.0381,  0.0069, -0.0079],\n",
              "                        [ 0.0405,  0.0016, -0.0005]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-0.0135, -0.0134,  0.0125],\n",
              "                        [ 0.0304,  0.0061,  0.0381],\n",
              "                        [-0.0146,  0.0262, -0.0056]],\n",
              "              \n",
              "                       [[-0.0217,  0.0230, -0.0065],\n",
              "                        [-0.0019,  0.0374,  0.0007],\n",
              "                        [ 0.0043,  0.0253, -0.0385]],\n",
              "              \n",
              "                       [[-0.0362, -0.0287, -0.0197],\n",
              "                        [ 0.0284, -0.0239,  0.0040],\n",
              "                        [-0.0093,  0.0121,  0.0079]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.0334,  0.0275, -0.0250],\n",
              "                        [-0.0229,  0.0090, -0.0215],\n",
              "                        [ 0.0040,  0.0233,  0.0207]],\n",
              "              \n",
              "                       [[-0.0314,  0.0164, -0.0290],\n",
              "                        [ 0.0215,  0.0266,  0.0213],\n",
              "                        [-0.0030,  0.0083,  0.0154]],\n",
              "              \n",
              "                       [[-0.0220, -0.0184,  0.0054],\n",
              "                        [ 0.0094,  0.0350,  0.0043],\n",
              "                        [-0.0291,  0.0148,  0.0135]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[ 0.0097, -0.0249,  0.0002],\n",
              "                        [-0.0203, -0.0344,  0.0400],\n",
              "                        [ 0.0326, -0.0111,  0.0025]],\n",
              "              \n",
              "                       [[-0.0163,  0.0088,  0.0360],\n",
              "                        [-0.0354,  0.0303,  0.0416],\n",
              "                        [ 0.0150,  0.0349, -0.0378]],\n",
              "              \n",
              "                       [[ 0.0076, -0.0309,  0.0407],\n",
              "                        [ 0.0180, -0.0406, -0.0390],\n",
              "                        [-0.0294,  0.0218,  0.0011]]]], device='cuda:0')),\n",
              "             ('conv_block2.3.bias',\n",
              "              tensor([ 0.0328, -0.0114,  0.0355, -0.0027,  0.0382,  0.0038, -0.0208, -0.0164,\n",
              "                       0.0328,  0.0005, -0.0306,  0.0248,  0.0133, -0.0225,  0.0114, -0.0253,\n",
              "                       0.0018,  0.0210,  0.0249,  0.0031,  0.0293, -0.0267, -0.0253,  0.0276,\n",
              "                       0.0143, -0.0393,  0.0066,  0.0021,  0.0109,  0.0201, -0.0168, -0.0397,\n",
              "                       0.0303,  0.0293, -0.0321, -0.0225,  0.0329, -0.0019, -0.0177,  0.0318,\n",
              "                      -0.0244,  0.0338, -0.0108, -0.0190,  0.0314, -0.0280, -0.0028, -0.0079,\n",
              "                       0.0109, -0.0228, -0.0318,  0.0314, -0.0373, -0.0333, -0.0281, -0.0379,\n",
              "                      -0.0038,  0.0085, -0.0037, -0.0351, -0.0129, -0.0396,  0.0115,  0.0339],\n",
              "                     device='cuda:0')),\n",
              "             ('conv_block2.4.weight',\n",
              "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')),\n",
              "             ('conv_block2.4.bias',\n",
              "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "                     device='cuda:0')),\n",
              "             ('conv_block2.4.running_mean',\n",
              "              tensor([-0.4204, -0.2545,  0.0244, -0.1285,  0.1650,  0.0484,  0.1148, -0.2021,\n",
              "                      -0.0041,  0.1771, -0.1174,  0.0534,  0.2051,  0.0559, -0.1023,  0.1461,\n",
              "                       0.2067,  0.0928,  0.1025,  0.0492,  0.1748,  0.2481,  0.1630,  0.1631,\n",
              "                      -0.2642,  0.1694, -0.1949,  0.0138,  0.0044,  0.3530, -0.3613,  0.0559,\n",
              "                       0.2528, -0.3965, -0.1205,  0.1863,  0.0271,  0.1810, -0.0617,  0.0493,\n",
              "                       0.0039,  0.3841, -0.3358, -0.0491,  0.3053,  0.0758, -0.1390, -0.0632,\n",
              "                      -0.0194, -0.2281,  0.2399, -0.0275,  0.1108, -0.1912,  0.2242, -0.1789,\n",
              "                       0.0575,  0.2679, -0.0691, -0.3497,  0.1897, -0.1082,  0.4068, -0.0280],\n",
              "                     device='cuda:0')),\n",
              "             ('conv_block2.4.running_var',\n",
              "              tensor([0.1155, 0.0922, 0.1220, 0.1045, 0.0896, 0.1177, 0.1624, 0.1034, 0.0912,\n",
              "                      0.1022, 0.0896, 0.0893, 0.1070, 0.1363, 0.0849, 0.1410, 0.1385, 0.0772,\n",
              "                      0.0785, 0.1555, 0.1013, 0.1010, 0.2344, 0.1307, 0.1681, 0.1600, 0.1741,\n",
              "                      0.1090, 0.0886, 0.1259, 0.1271, 0.1118, 0.1257, 0.1608, 0.1195, 0.1736,\n",
              "                      0.1058, 0.1479, 0.1756, 0.0942, 0.1247, 0.2506, 0.0935, 0.1101, 0.2811,\n",
              "                      0.1104, 0.1214, 0.0953, 0.1056, 0.0890, 0.1311, 0.1566, 0.1090, 0.1394,\n",
              "                      0.1374, 0.1074, 0.0829, 0.1485, 0.0975, 0.0849, 0.0867, 0.0883, 0.1760,\n",
              "                      0.1151], device='cuda:0')),\n",
              "             ('conv_block2.4.num_batches_tracked',\n",
              "              tensor(1875, device='cuda:0')),\n",
              "             ('conv_block3.0.weight',\n",
              "              tensor([[[[-1.8139e-02,  1.1419e-02, -3.4708e-02],\n",
              "                        [ 2.3491e-02, -3.4965e-03,  1.7423e-02],\n",
              "                        [-1.2978e-02,  3.9910e-02, -3.6474e-02]],\n",
              "              \n",
              "                       [[-3.5826e-02, -8.6206e-03, -7.0093e-03],\n",
              "                        [ 4.1308e-02, -1.7376e-02, -1.6678e-02],\n",
              "                        [ 1.5190e-02,  1.5545e-02, -1.1953e-02]],\n",
              "              \n",
              "                       [[ 1.6627e-02, -2.2310e-02,  1.6551e-02],\n",
              "                        [-2.4203e-02, -1.7581e-04, -4.0636e-02],\n",
              "                        [-2.0552e-02,  2.9975e-02, -1.2587e-05]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[ 2.1278e-03,  1.6696e-02, -3.4420e-02],\n",
              "                        [-2.8331e-02,  3.8460e-02,  3.7464e-03],\n",
              "                        [ 8.0674e-03,  5.7392e-03,  1.1819e-02]],\n",
              "              \n",
              "                       [[-4.1439e-03, -2.3702e-02, -8.9476e-03],\n",
              "                        [ 4.4867e-03,  7.4471e-03,  1.7121e-02],\n",
              "                        [ 8.0366e-03, -1.3676e-02,  2.4545e-02]],\n",
              "              \n",
              "                       [[-6.7822e-03,  2.6465e-02, -2.8622e-02],\n",
              "                        [-2.6745e-02, -3.5719e-02,  3.2574e-04],\n",
              "                        [-3.6637e-02,  3.3293e-02,  1.9557e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[-1.2888e-02,  2.1517e-02,  3.4318e-02],\n",
              "                        [-3.8317e-02,  1.9009e-02, -3.6907e-02],\n",
              "                        [ 2.7364e-02,  2.6233e-02,  2.7041e-02]],\n",
              "              \n",
              "                       [[-7.6087e-03,  4.8164e-03, -3.2358e-02],\n",
              "                        [ 2.2469e-02, -3.8773e-02, -1.7847e-02],\n",
              "                        [-1.1262e-02,  1.3494e-02,  5.3366e-03]],\n",
              "              \n",
              "                       [[-1.3287e-02, -1.2612e-02,  1.3617e-02],\n",
              "                        [ 2.1007e-02,  1.3146e-02, -3.4291e-02],\n",
              "                        [-2.4983e-02,  3.9728e-02, -2.4698e-02]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-1.0858e-02,  2.8422e-02, -4.0183e-02],\n",
              "                        [ 4.0441e-02, -2.1258e-02,  2.9935e-02],\n",
              "                        [-3.3567e-02,  2.0922e-02, -5.6564e-03]],\n",
              "              \n",
              "                       [[-3.7426e-03,  3.3296e-02, -1.9981e-02],\n",
              "                        [ 3.7882e-03,  2.5669e-02,  2.8662e-02],\n",
              "                        [ 8.9385e-03,  8.4818e-03,  1.0626e-03]],\n",
              "              \n",
              "                       [[-1.4227e-02, -3.4739e-02,  3.4804e-02],\n",
              "                        [-8.9974e-03,  1.2117e-02,  5.1038e-03],\n",
              "                        [-1.1383e-02, -2.8353e-02, -3.9171e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[-2.6035e-02, -1.5102e-02,  4.0461e-02],\n",
              "                        [ 9.3242e-03,  1.2437e-02, -9.9961e-03],\n",
              "                        [-2.7559e-02,  3.1871e-03,  4.1005e-02]],\n",
              "              \n",
              "                       [[-9.0202e-04,  1.0801e-02,  3.4505e-02],\n",
              "                        [ 7.0008e-03, -4.6761e-03,  2.1824e-02],\n",
              "                        [ 2.8947e-02,  3.2057e-02,  3.5883e-02]],\n",
              "              \n",
              "                       [[ 3.6849e-02, -2.8804e-02, -1.8900e-02],\n",
              "                        [-3.8982e-02, -2.7288e-02,  2.3235e-02],\n",
              "                        [-1.9547e-02,  3.1403e-02, -2.0794e-02]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-2.7771e-02,  2.4700e-02,  2.6489e-03],\n",
              "                        [-3.4433e-02,  7.0373e-03, -2.9856e-03],\n",
              "                        [ 1.1932e-02,  9.6778e-03,  1.1409e-04]],\n",
              "              \n",
              "                       [[-3.4655e-02, -7.0831e-03,  3.1916e-03],\n",
              "                        [ 3.1405e-02,  3.9940e-02,  3.5826e-02],\n",
              "                        [-3.8989e-02, -1.5808e-02, -1.5789e-03]],\n",
              "              \n",
              "                       [[-2.4674e-02, -1.9180e-02, -1.1556e-03],\n",
              "                        [-7.0002e-03,  3.1155e-02, -3.6088e-02],\n",
              "                        [ 4.1456e-03, -2.5887e-02, -1.8292e-02]]],\n",
              "              \n",
              "              \n",
              "                      ...,\n",
              "              \n",
              "              \n",
              "                      [[[ 3.6332e-02, -3.0800e-02, -2.9387e-02],\n",
              "                        [ 1.3751e-02,  8.2095e-03, -3.2957e-02],\n",
              "                        [ 3.8546e-02,  1.2561e-02,  3.4700e-02]],\n",
              "              \n",
              "                       [[-3.9860e-03,  5.4131e-03,  3.7233e-02],\n",
              "                        [-8.4910e-03, -8.9009e-03,  3.3773e-02],\n",
              "                        [ 7.0687e-03,  2.0872e-02,  5.5371e-03]],\n",
              "              \n",
              "                       [[-2.0219e-02, -2.1370e-02, -4.1142e-02],\n",
              "                        [ 3.1411e-03, -1.4873e-02,  2.4314e-02],\n",
              "                        [ 1.9054e-02,  3.4074e-02, -2.2090e-02]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[ 8.8825e-03, -1.0756e-02,  1.8924e-02],\n",
              "                        [-7.6498e-03, -8.7154e-03,  2.7370e-02],\n",
              "                        [-7.3583e-03, -1.4655e-02,  1.3117e-03]],\n",
              "              \n",
              "                       [[-3.3838e-02, -2.3960e-02, -3.7703e-02],\n",
              "                        [ 3.9588e-02,  4.1401e-02, -1.9385e-04],\n",
              "                        [ 1.9159e-02, -3.4701e-02,  3.2817e-02]],\n",
              "              \n",
              "                       [[-1.3999e-02,  3.9062e-02,  3.2412e-02],\n",
              "                        [ 3.5072e-02, -4.0823e-03,  2.7589e-02],\n",
              "                        [ 3.1385e-02,  1.3291e-02, -3.8093e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 2.2794e-02,  3.7837e-02,  3.7543e-02],\n",
              "                        [ 3.8791e-02, -3.0306e-02, -5.0146e-04],\n",
              "                        [ 2.1054e-02, -6.3131e-03, -4.0117e-02]],\n",
              "              \n",
              "                       [[-3.1025e-02,  3.0514e-02,  3.3462e-02],\n",
              "                        [-9.8681e-03, -1.9446e-02,  3.6243e-02],\n",
              "                        [ 2.6499e-03, -2.3384e-02,  1.7228e-03]],\n",
              "              \n",
              "                       [[ 1.1332e-02, -2.4107e-02,  3.3718e-02],\n",
              "                        [ 1.6075e-02,  1.7163e-02, -1.3601e-02],\n",
              "                        [-1.1815e-02, -1.2413e-02, -3.5607e-02]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[ 4.1380e-02,  1.2465e-02,  1.7898e-02],\n",
              "                        [ 2.5939e-02,  2.4324e-02, -2.2935e-02],\n",
              "                        [ 3.0396e-02, -3.5120e-02, -6.6787e-03]],\n",
              "              \n",
              "                       [[ 3.6363e-02, -1.4557e-02,  1.9846e-02],\n",
              "                        [ 8.6210e-03, -1.8192e-02,  2.1386e-02],\n",
              "                        [ 2.5085e-02, -3.6189e-02,  3.7437e-03]],\n",
              "              \n",
              "                       [[ 2.7781e-02, -2.4566e-02, -2.1777e-02],\n",
              "                        [ 2.0878e-02, -2.2026e-02, -3.0361e-02],\n",
              "                        [-1.9438e-03,  3.9951e-02,  1.7272e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[-4.0286e-02, -4.0740e-02, -3.7576e-03],\n",
              "                        [-2.4200e-02, -5.9493e-03, -1.7418e-02],\n",
              "                        [ 3.3680e-02,  2.6655e-02, -4.8884e-03]],\n",
              "              \n",
              "                       [[ 1.3497e-02, -3.9899e-02, -1.0882e-02],\n",
              "                        [ 3.3741e-02, -3.5049e-03, -2.6998e-02],\n",
              "                        [ 2.4204e-02,  3.8317e-02,  5.2257e-03]],\n",
              "              \n",
              "                       [[-1.2184e-02,  1.7180e-02, -3.5632e-02],\n",
              "                        [ 3.2895e-03,  2.2270e-02,  1.0539e-02],\n",
              "                        [ 3.4174e-02, -2.9966e-02, -1.1904e-02]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-8.8979e-03, -3.7437e-02,  2.7787e-02],\n",
              "                        [-5.7484e-05, -3.9388e-02,  2.8415e-02],\n",
              "                        [-3.4600e-02,  1.5968e-02, -1.3081e-02]],\n",
              "              \n",
              "                       [[ 4.0539e-02, -3.6359e-03, -1.2146e-02],\n",
              "                        [ 8.7801e-03, -4.1515e-02,  2.9796e-02],\n",
              "                        [-1.4523e-02,  3.8710e-02, -3.5487e-02]],\n",
              "              \n",
              "                       [[-2.0170e-02,  9.9244e-03,  1.0309e-02],\n",
              "                        [ 2.2728e-02, -3.7921e-02,  2.0980e-03],\n",
              "                        [-1.3419e-03,  5.1706e-03, -3.6669e-02]]]], device='cuda:0')),\n",
              "             ('conv_block3.0.bias',\n",
              "              tensor([-0.0065, -0.0251,  0.0205,  0.0120,  0.0268, -0.0402,  0.0334, -0.0308,\n",
              "                       0.0052,  0.0368,  0.0284,  0.0152, -0.0274, -0.0347, -0.0396, -0.0268,\n",
              "                      -0.0239,  0.0033, -0.0094, -0.0218,  0.0342, -0.0270, -0.0173,  0.0088,\n",
              "                       0.0235,  0.0071, -0.0141,  0.0012,  0.0401,  0.0235,  0.0255,  0.0365,\n",
              "                       0.0228, -0.0124, -0.0068, -0.0340,  0.0150, -0.0043,  0.0320,  0.0333,\n",
              "                      -0.0007, -0.0127, -0.0364, -0.0292, -0.0136,  0.0241, -0.0196, -0.0272,\n",
              "                       0.0363,  0.0133,  0.0260,  0.0278, -0.0369,  0.0247, -0.0278, -0.0184,\n",
              "                       0.0390, -0.0311,  0.0065,  0.0028, -0.0038,  0.0319, -0.0199,  0.0335,\n",
              "                       0.0128, -0.0231, -0.0239,  0.0224,  0.0264,  0.0157,  0.0405, -0.0186,\n",
              "                       0.0132, -0.0305,  0.0101, -0.0054, -0.0130,  0.0277,  0.0325, -0.0044,\n",
              "                       0.0009, -0.0057, -0.0116, -0.0101, -0.0113, -0.0303, -0.0339,  0.0075,\n",
              "                      -0.0223, -0.0053, -0.0238,  0.0348,  0.0354,  0.0322, -0.0059,  0.0017,\n",
              "                      -0.0223,  0.0226,  0.0286,  0.0157,  0.0243,  0.0413,  0.0191, -0.0086,\n",
              "                      -0.0401, -0.0017,  0.0219,  0.0191,  0.0102,  0.0243, -0.0393,  0.0046,\n",
              "                      -0.0278, -0.0256, -0.0406,  0.0275,  0.0314,  0.0340,  0.0090, -0.0280,\n",
              "                      -0.0403, -0.0069,  0.0355, -0.0370,  0.0298, -0.0306,  0.0376, -0.0244],\n",
              "                     device='cuda:0')),\n",
              "             ('conv_block3.1.weight',\n",
              "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "                      1., 1.], device='cuda:0')),\n",
              "             ('conv_block3.1.bias',\n",
              "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "                      0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
              "             ('conv_block3.1.running_mean',\n",
              "              tensor([ 0.1315,  0.3174,  0.1030,  0.3923, -0.1522,  0.0804,  0.9084,  0.2174,\n",
              "                       0.0274, -0.2755, -0.1397, -0.3535, -0.2565, -0.2335,  0.3664,  0.1716,\n",
              "                      -0.8177, -0.0958,  0.1966,  0.6709,  0.2633, -0.4654,  0.8850, -0.2341,\n",
              "                       0.4892, -0.2588,  0.0435, -0.4743, -0.0605, -0.2536,  0.6218,  0.5360,\n",
              "                       0.2458,  0.4656, -0.7000, -0.0083,  0.7016,  0.0513,  0.7876, -0.4153,\n",
              "                      -0.1481, -0.3773, -0.1913, -0.4195, -0.3283,  0.7759, -0.2299,  0.4787,\n",
              "                      -0.2562, -0.3495,  0.4673,  0.2565, -0.3426,  0.1360,  0.6510,  0.2069,\n",
              "                      -0.4774, -0.5137, -0.4242,  0.2381, -0.0548,  0.3634, -0.2288,  0.1679,\n",
              "                       0.2242,  0.2180, -0.2061, -0.2158,  0.6578,  0.7172,  0.5061,  0.0545,\n",
              "                       0.5153, -0.1408, -0.7093,  0.2761, -0.3928, -0.1642, -0.3582,  0.1198,\n",
              "                      -0.2743, -0.1649, -0.2309,  0.0754, -0.1022,  0.0373,  0.2438, -0.2157,\n",
              "                       0.2857,  0.3280, -1.1677, -0.1582, -0.2337,  0.3094, -0.3225, -0.1810,\n",
              "                       0.4027, -0.1476, -0.1155, -0.0189,  0.4836,  0.2437, -0.1270, -0.8703,\n",
              "                       0.6708,  0.2115,  0.3666,  0.0470,  0.5570,  0.1819, -0.4060,  0.2753,\n",
              "                       0.4040, -0.1790, -0.3498, -0.2680, -0.0759,  0.0941,  0.3429, -0.2092,\n",
              "                      -0.0168, -0.5899,  0.2429, -0.2009, -0.6852, -0.6233, -0.0177, -0.3714],\n",
              "                     device='cuda:0')),\n",
              "             ('conv_block3.1.running_var',\n",
              "              tensor([0.3304, 0.3985, 0.3513, 0.3117, 0.3285, 0.3226, 0.9032, 0.4511, 0.2944,\n",
              "                      0.3718, 0.2901, 0.3056, 0.2880, 0.3445, 0.3223, 0.3293, 0.4667, 0.3051,\n",
              "                      0.4776, 0.3545, 0.3175, 0.5103, 0.5270, 0.4249, 0.3950, 0.4365, 0.2760,\n",
              "                      0.3025, 0.3090, 0.3674, 0.4385, 0.3505, 0.3829, 0.5033, 0.4991, 0.4519,\n",
              "                      0.4330, 0.3176, 0.3236, 0.4564, 0.3669, 0.3291, 0.3401, 0.3378, 0.4518,\n",
              "                      0.6194, 0.4461, 0.4181, 0.3375, 0.5165, 0.4185, 0.3427, 0.3442, 0.3012,\n",
              "                      0.5433, 0.4711, 0.4860, 0.5302, 0.5791, 0.3132, 0.3068, 0.4178, 0.3375,\n",
              "                      0.5272, 0.3139, 0.3092, 0.3809, 0.6337, 0.5119, 0.4113, 0.3637, 0.3540,\n",
              "                      0.3792, 0.3176, 0.5175, 0.4683, 0.3796, 0.3511, 0.4576, 0.3886, 0.3666,\n",
              "                      0.3144, 0.2835, 0.3368, 0.3344, 0.3434, 0.5389, 0.2779, 0.3760, 0.4989,\n",
              "                      0.5879, 0.2696, 0.3920, 0.3678, 0.4858, 0.3378, 0.3750, 0.3282, 0.3008,\n",
              "                      0.3924, 0.4712, 0.3629, 0.2848, 0.4601, 0.3441, 0.3845, 0.5150, 0.3130,\n",
              "                      0.3905, 0.4171, 0.3867, 0.4094, 0.3550, 0.3373, 0.2940, 0.4460, 0.3024,\n",
              "                      0.4403, 0.4342, 0.3576, 0.3052, 0.4157, 0.3015, 0.3061, 0.5432, 0.3655,\n",
              "                      0.3672, 0.3365], device='cuda:0')),\n",
              "             ('conv_block3.1.num_batches_tracked',\n",
              "              tensor(1875, device='cuda:0')),\n",
              "             ('fc.0.weight',\n",
              "              tensor([[ 7.3047e-03, -2.8149e-02, -3.7107e-03,  ..., -2.3925e-02,\n",
              "                       -6.3924e-03,  2.5159e-02],\n",
              "                      [ 2.4822e-02,  1.4175e-02, -2.3736e-02,  ..., -1.2044e-02,\n",
              "                       -2.7981e-02, -1.6218e-02],\n",
              "                      [ 2.7441e-02,  2.0087e-03,  2.2261e-02,  ..., -2.3281e-02,\n",
              "                       -2.3123e-02, -1.7201e-02],\n",
              "                      ...,\n",
              "                      [-2.9151e-02,  8.0185e-03,  1.1963e-02,  ..., -1.9359e-02,\n",
              "                       -2.6500e-02,  5.3843e-05],\n",
              "                      [-3.8310e-03,  1.9051e-02,  2.4367e-02,  ...,  2.5206e-02,\n",
              "                       -2.8478e-02,  1.2569e-02],\n",
              "                      [-8.4215e-03,  2.6072e-02, -1.1623e-02,  ..., -7.7762e-03,\n",
              "                       -1.1668e-02,  2.5346e-02]], device='cuda:0')),\n",
              "             ('fc.0.bias',\n",
              "              tensor([ 7.2010e-03,  1.9772e-02,  2.0892e-02, -2.0038e-02, -2.7181e-02,\n",
              "                       2.6395e-02, -2.5070e-03,  1.7907e-02, -1.9460e-02,  3.5407e-04,\n",
              "                      -5.2350e-03, -1.2095e-03, -7.8136e-03, -1.7095e-02,  1.6713e-02,\n",
              "                      -2.3372e-02,  2.1043e-02,  1.2832e-03, -2.4413e-02, -2.2402e-02,\n",
              "                       6.4126e-03, -1.2986e-02,  3.1018e-03,  1.1507e-02,  1.4852e-02,\n",
              "                      -9.5273e-03,  7.6039e-03,  6.5424e-03, -1.4856e-02,  1.3302e-02,\n",
              "                      -1.9620e-02,  1.1712e-02,  9.0253e-03, -2.6386e-02, -1.0808e-02,\n",
              "                       2.7787e-02, -1.8118e-02, -2.4056e-02,  6.7409e-03,  1.4415e-02,\n",
              "                       5.9026e-03, -1.5882e-02,  4.2235e-03,  1.1411e-02, -2.4056e-02,\n",
              "                      -2.6428e-03,  4.1073e-03,  1.4623e-02, -1.7607e-02,  6.8427e-03,\n",
              "                      -5.3424e-03,  2.2983e-02,  5.9839e-04, -1.7249e-02, -1.6204e-02,\n",
              "                      -5.8100e-03, -7.7563e-04, -5.4904e-03, -1.4944e-02, -1.4698e-03,\n",
              "                       1.4489e-03,  8.7214e-03,  4.3509e-03, -1.9442e-02,  1.9642e-02,\n",
              "                       2.6074e-02, -1.7918e-02,  1.3712e-02, -7.6473e-03, -2.8071e-02,\n",
              "                       1.5063e-02,  1.4847e-02,  8.5149e-03, -2.5426e-03,  1.6457e-03,\n",
              "                      -4.6935e-04, -1.8481e-02,  1.8507e-02,  1.0979e-02,  1.0359e-02,\n",
              "                      -2.6759e-02, -7.6012e-03,  5.1705e-03,  4.5532e-03, -2.7281e-02,\n",
              "                       3.5973e-04,  1.2471e-02,  2.7128e-02,  2.7215e-02,  2.7008e-03,\n",
              "                       2.8380e-02,  2.4812e-03, -4.3366e-03,  2.1689e-02,  2.1257e-02,\n",
              "                      -4.2892e-03,  7.4917e-03,  2.5251e-02, -2.5783e-02, -2.1809e-02,\n",
              "                      -2.2367e-02,  1.2224e-02,  6.1157e-03, -5.0578e-03,  7.5250e-03,\n",
              "                       8.8275e-03, -9.8985e-03,  2.2708e-02, -1.4027e-02, -2.6128e-02,\n",
              "                      -5.1142e-03, -2.3561e-02,  2.5618e-02, -1.8101e-02,  2.1404e-02,\n",
              "                       2.0995e-02,  1.0057e-02,  1.2298e-02, -6.8741e-03,  1.8397e-03,\n",
              "                      -2.6043e-02, -2.8676e-02,  2.3124e-02,  2.0898e-02,  1.8438e-03,\n",
              "                       8.8990e-03, -2.1078e-02, -2.1562e-02, -2.4629e-02,  2.2981e-02,\n",
              "                       2.6206e-02, -2.5413e-02, -1.0199e-02,  1.3673e-02,  1.2379e-02,\n",
              "                       1.3865e-03,  2.1758e-02, -2.6485e-02,  1.6406e-02, -2.3117e-02,\n",
              "                      -1.2627e-02,  1.5706e-03,  1.7545e-02,  2.8677e-02,  2.6854e-02,\n",
              "                      -1.2609e-02,  2.6897e-02, -2.0159e-02, -1.9584e-02,  1.8384e-02,\n",
              "                       2.8707e-02,  2.3267e-03,  1.4655e-02,  2.7724e-02, -2.3043e-02,\n",
              "                       1.6851e-02, -9.5322e-03,  2.3748e-02,  1.2467e-02,  1.3066e-02,\n",
              "                      -2.2551e-03, -2.5111e-02,  2.6982e-03, -5.5327e-03, -2.1050e-03,\n",
              "                      -1.9883e-02, -1.8467e-02,  1.6263e-02,  1.5555e-02, -2.0762e-03,\n",
              "                       2.2079e-02,  2.7081e-02, -1.3326e-02,  5.4685e-03,  2.8284e-02,\n",
              "                      -1.7503e-02,  1.1958e-02, -1.9867e-02,  5.5896e-03, -5.1221e-04,\n",
              "                       5.8614e-03,  2.5064e-02,  2.2073e-02,  1.3493e-02, -9.5260e-03,\n",
              "                      -2.6047e-02, -8.1200e-03,  7.4242e-03,  1.8742e-02, -2.0436e-02,\n",
              "                      -4.7486e-03, -1.1156e-02,  1.4824e-02, -2.0956e-02,  1.3187e-02,\n",
              "                       2.2902e-02, -2.7598e-02, -2.6600e-02,  9.0329e-03,  3.5608e-03,\n",
              "                      -1.0311e-02, -1.0758e-02,  2.5408e-02, -1.1426e-03, -2.5546e-02,\n",
              "                       1.0072e-02,  1.7572e-02, -1.8658e-03, -2.3472e-02, -2.0623e-02,\n",
              "                      -6.2620e-03, -2.3904e-02, -1.4048e-02,  1.6833e-02, -1.5502e-02,\n",
              "                       2.9047e-02, -1.0011e-02,  2.4973e-02,  9.6529e-04,  5.3895e-03,\n",
              "                      -6.6265e-04, -2.8481e-02,  1.6280e-02,  3.9629e-04,  1.7720e-02,\n",
              "                      -2.3120e-02,  2.0434e-02, -8.1220e-03,  3.4400e-03,  7.0751e-05,\n",
              "                      -1.4482e-03, -2.7352e-03, -2.4737e-02, -1.2006e-02, -2.2901e-02,\n",
              "                       5.0255e-03, -2.4996e-02,  1.6549e-02,  7.5036e-03, -1.6442e-02,\n",
              "                      -3.4959e-03, -1.7904e-02,  2.6357e-02,  8.4554e-05,  2.5940e-02,\n",
              "                      -2.5178e-02, -2.0502e-04, -2.9242e-02, -2.6870e-02,  1.1918e-02,\n",
              "                       2.5230e-02,  2.0924e-02, -1.6067e-02,  1.4451e-02,  2.0180e-02,\n",
              "                      -3.5390e-03], device='cuda:0')),\n",
              "             ('fc.3.weight',\n",
              "              tensor([[ 0.0230, -0.0242,  0.0331,  ..., -0.0349,  0.0437,  0.0464],\n",
              "                      [ 0.0254,  0.0183,  0.0153,  ..., -0.0614,  0.0162,  0.0571],\n",
              "                      [-0.0378, -0.0604, -0.0423,  ...,  0.0252,  0.0373, -0.0463],\n",
              "                      ...,\n",
              "                      [-0.0007, -0.0476,  0.0363,  ..., -0.0446, -0.0029, -0.0415],\n",
              "                      [-0.0247, -0.0574,  0.0197,  ..., -0.0180,  0.0362,  0.0534],\n",
              "                      [ 0.0428,  0.0327,  0.0038,  ...,  0.0406, -0.0481,  0.0144]],\n",
              "                     device='cuda:0')),\n",
              "             ('fc.3.bias',\n",
              "              tensor([-0.0471,  0.0161, -0.0424, -0.0323,  0.0372,  0.0042, -0.0564, -0.0585,\n",
              "                      -0.0046,  0.0122, -0.0131, -0.0227,  0.0430,  0.0281, -0.0289, -0.0357,\n",
              "                      -0.0291,  0.0534,  0.0221, -0.0128, -0.0095,  0.0247,  0.0037, -0.0593,\n",
              "                       0.0324,  0.0044, -0.0569,  0.0018, -0.0288,  0.0103, -0.0114,  0.0266,\n",
              "                      -0.0183,  0.0476, -0.0300, -0.0545, -0.0604, -0.0376, -0.0137,  0.0565,\n",
              "                       0.0621, -0.0612,  0.0069,  0.0504,  0.0221, -0.0163,  0.0067,  0.0457,\n",
              "                       0.0040,  0.0602,  0.0483, -0.0097, -0.0111, -0.0092,  0.0063,  0.0113,\n",
              "                      -0.0103,  0.0074, -0.0201, -0.0053, -0.0165,  0.0103, -0.0585, -0.0344,\n",
              "                      -0.0161, -0.0288, -0.0084,  0.0326, -0.0447, -0.0194, -0.0085,  0.0102,\n",
              "                       0.0476,  0.0471,  0.0373, -0.0204, -0.0551,  0.0013, -0.0475, -0.0108,\n",
              "                      -0.0304,  0.0580,  0.0007, -0.0516,  0.0587,  0.0599,  0.0019,  0.0019,\n",
              "                       0.0541, -0.0228, -0.0609,  0.0590,  0.0444, -0.0529, -0.0049,  0.0253,\n",
              "                      -0.0176,  0.0485, -0.0086, -0.0023,  0.0199, -0.0042, -0.0200, -0.0588,\n",
              "                      -0.0502,  0.0155, -0.0475, -0.0271,  0.0526, -0.0522, -0.0313,  0.0454,\n",
              "                      -0.0590,  0.0516, -0.0429, -0.0384, -0.0402, -0.0500, -0.0187, -0.0302,\n",
              "                      -0.0483,  0.0107, -0.0367,  0.0563,  0.0561,  0.0402,  0.0408, -0.0419],\n",
              "                     device='cuda:0')),\n",
              "             ('fc.6.weight',\n",
              "              tensor([[-0.0140, -0.0853, -0.0219,  ..., -0.0582, -0.0061,  0.0586],\n",
              "                      [ 0.0312,  0.0729, -0.0234,  ..., -0.0505,  0.0406, -0.0548],\n",
              "                      [ 0.0607,  0.0527,  0.0135,  ..., -0.0189, -0.0053,  0.0003],\n",
              "                      ...,\n",
              "                      [ 0.0832,  0.0631, -0.0844,  ..., -0.0842, -0.0516,  0.0410],\n",
              "                      [ 0.0143,  0.0597, -0.0183,  ...,  0.0087,  0.0448,  0.0582],\n",
              "                      [ 0.0016,  0.0302, -0.0285,  ...,  0.0533,  0.0396, -0.0207]],\n",
              "                     device='cuda:0')),\n",
              "             ('fc.6.bias',\n",
              "              tensor([-0.0404, -0.0645, -0.0540,  0.0785,  0.0521,  0.0359, -0.0800,  0.0468,\n",
              "                       0.0095,  0.0348], device='cuda:0'))])"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from pathlib import Path\n",
        "#Download helper functions\n",
        "if Path('helper_functions.py').is_file():\n",
        "  print('File already exists, skipping download')\n",
        "else:\n",
        "  print('Downloading file')\n",
        "  request = requests.get(\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/af6548e52663c8395fe2777bd0fbfd6ac85fd6f8/helper_functions.py\")\n",
        "  with open('helper_functions.py','wb') as f:\n",
        "    f.write(request.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4qS1KRkwKNH",
        "outputId": "79fe7aa6-8103-4413-c54b-e8b02c6d5c59"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File already exists, skipping download\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from helper_functions import accuracy_fn\n",
        "\n",
        "loss_fn =nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(params = model_0.parameters(),\n",
        "                            lr=0.1)\n"
      ],
      "metadata": {
        "id": "vbhcy8brxCx-"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating a function to time our experiments\n",
        "from timeit import default_timer as timer\n",
        "def print_train_time(start:float,\n",
        "                     end: float,\n",
        "                     device: torch.device = None):\n",
        "  total_time = end-start\n",
        "  print(f\"Train time on {device}: {total_time:.3f} seconds\")\n",
        "  return total_time"
      ],
      "metadata": {
        "id": "wJndVj-vxP6u"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_time =timer()\n",
        "end_time=timer()\n",
        "print_train_time(start=start_time, end=end_time, device= 'cpu')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_MMmm4w6yYoz",
        "outputId": "fcea4f77-fd2d-41a1-e263-bcf9f0de3d48"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train time on cpu: 0.000 seconds\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.9448000077536562e-05"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in tqdm(range(epochs)):\n",
        "    print(f'Epoch: {epoch}\\n-----------')\n",
        "    train_loss = 0\n",
        "    for batch, (X, y) in enumerate(train_dataloader):\n",
        "        X, y = X.to(device), y.to(device)  # <-- move to device\n",
        "\n",
        "        model_0.train()\n",
        "        y_pred = model_0(X)\n",
        "        loss = loss_fn(y_pred, y)\n",
        "        train_loss += loss\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 400 == 0:\n",
        "            print(f'Looked at {batch * len(X)}/{len(train_dataloader.dataset)} samples')\n",
        "\n",
        "    train_loss /= len(train_dataloader)\n",
        "\n",
        "    # Evaluation\n",
        "    test_loss, test_acc = 0, 0\n",
        "    model_0.eval()\n",
        "    with torch.inference_mode():\n",
        "      for X, y in test_dataloader:\n",
        "          X, y = X.to(device), y.to(device)\n",
        "          test_pred = model_0(X)\n",
        "          test_loss += loss_fn(test_pred, y).item()\n",
        "          test_acc += accuracy_fn(y_true=y, y_pred=test_pred.argmax(dim=1))\n",
        "\n",
        "\n",
        "\n",
        "    test_loss /= len(test_dataloader)\n",
        "    test_acc /= len(test_dataloader)\n",
        "    print(f'Train loss: {train_loss:.5f} | Test loss: {test_loss:.5f} | Test acc: {test_acc:.2f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 743,
          "referenced_widgets": [
            "4bab276b4e714acc8d5d243c18af189d",
            "025751e0da5e4ed8b6a5b034f381540b",
            "d9bc103f888d4c3f92775328c6b38472",
            "c5150cc14b504a50888234a04b8d9042",
            "4ed24c71cdc8486da7158ed09eab8737",
            "ac9b86a464a042d8a1e610679d989f79",
            "3860278a28b94405a013c6bb5e69d318",
            "23627c8c87254cbf9dc83575f248d5a7",
            "a0db86fa7759470eb8e923186c18e324",
            "a29d604d807942b89b5b368428f750e6",
            "167efdae82c442fa9457e0c140358e22"
          ]
        },
        "id": "aGaw-MhLyoD2",
        "outputId": "f65347e8-e8c6-47a4-a076-60251b393768"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4bab276b4e714acc8d5d243c18af189d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0\n",
            "-----------\n",
            "Looked at 0/60000 samples\n",
            "Looked at 12800/60000 samples\n",
            "Looked at 25600/60000 samples\n",
            "Looked at 38400/60000 samples\n",
            "Looked at 51200/60000 samples\n",
            "Train loss: 0.11040 | Test loss: 0.03679 | Test acc: 98.97\n",
            "Epoch: 1\n",
            "-----------\n",
            "Looked at 0/60000 samples\n",
            "Looked at 12800/60000 samples\n",
            "Looked at 25600/60000 samples\n",
            "Looked at 38400/60000 samples\n",
            "Looked at 51200/60000 samples\n",
            "Train loss: 0.07953 | Test loss: 0.03626 | Test acc: 99.01\n",
            "Epoch: 2\n",
            "-----------\n",
            "Looked at 0/60000 samples\n",
            "Looked at 12800/60000 samples\n",
            "Looked at 25600/60000 samples\n",
            "Looked at 38400/60000 samples\n",
            "Looked at 51200/60000 samples\n",
            "Train loss: 0.06905 | Test loss: 0.02652 | Test acc: 99.29\n",
            "Epoch: 3\n",
            "-----------\n",
            "Looked at 0/60000 samples\n",
            "Looked at 12800/60000 samples\n",
            "Looked at 25600/60000 samples\n",
            "Looked at 38400/60000 samples\n",
            "Looked at 51200/60000 samples\n",
            "Train loss: 0.05631 | Test loss: 0.02292 | Test acc: 99.36\n",
            "Epoch: 4\n",
            "-----------\n",
            "Looked at 0/60000 samples\n",
            "Looked at 12800/60000 samples\n",
            "Looked at 25600/60000 samples\n",
            "Looked at 38400/60000 samples\n",
            "Looked at 51200/60000 samples\n",
            "Train loss: 0.04804 | Test loss: 0.01865 | Test acc: 99.52\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. Make predictions and get results"
      ],
      "metadata": {
        "id": "zEAl8AH43tA8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "def eval_model(model: torch.nn.Module,\n",
        "               data_loader: torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               accuracy_fn):\n",
        "    loss, acc = 0, 0\n",
        "    model.eval()\n",
        "    with torch.inference_mode():\n",
        "        for x, y in tqdm(data_loader):\n",
        "            x, y = x.to(device), y.to(device)  # <-- move to device\n",
        "            y_pred = model(x)\n",
        "            loss += loss_fn(y_pred, y).item()\n",
        "            acc += accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=1))\n",
        "\n",
        "        loss /= len(data_loader)\n",
        "        acc /= len(data_loader)\n",
        "\n",
        "    return {\n",
        "    'Model Name': model.__class__.__name__,\n",
        "    'Model Loss': loss,\n",
        "    'Model Accuracy': acc\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "model_0_results = eval_model(model=model_0,\n",
        "                             data_loader=test_dataloader,\n",
        "                             loss_fn=loss_fn,\n",
        "                             accuracy_fn=accuracy_fn)\n",
        "model_0_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YWqPMbg2vAa",
        "outputId": "59d57c89-1fd3-4889-9b4b-3a657868cc49"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 313/313 [00:01<00:00, 235.84it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Model Name': 'FashionMNISTModelV0',\n",
              " 'Model Loss': 0.018645409659481235,\n",
              " 'Model Accuracy': 99.52076677316293}"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Pillow\n",
        "from PIL import ImageOps"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqbpFeXhX9aA",
        "outputId": "33a5cb9b-825a-426b-be25-e9c0f2d97e2d"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from PIL import Image, ImageOps\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model_0.to(device)\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((28, 28)),\n",
        "    transforms.Grayscale(num_output_channels=1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "def predict_image(image_path):\n",
        "    image = Image.open(image_path).convert('L')\n",
        "    image = ImageOps.invert(image)\n",
        "    image = transform(image).unsqueeze(0).to(device)\n",
        "    model_0.eval()\n",
        "    with torch.no_grad():\n",
        "        output = model_0(image)\n",
        "        _, predicted_class = torch.max(output, 1)\n",
        "    return predicted_class.item()\n",
        "\n",
        "image_path = '/content/1.jpg'\n",
        "predicted_class = predict_image(image_path)\n",
        "print(f'Predicted Class: {predicted_class}')\n",
        "print(f'Class Name: {class_names[predicted_class]}')\n",
        "\n",
        "def show_tensor_image(tensor_img):\n",
        "    img = tensor_img.squeeze().cpu().numpy()\n",
        "    plt.imshow(img, cmap='hot')\n",
        "    plt.axis('off')\n",
        "    plt.title(\"Preprocessed Image\")\n",
        "    plt.show()\n",
        "\n",
        "image_tensor = transform(ImageOps.invert(Image.open(image_path).convert('L')))\n",
        "show_tensor_image(image_tensor)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "A8XS8Ganc_fB",
        "outputId": "92a442f4-8826-416f-add4-28cdba588a05"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Class: 1\n",
            "Class Name: 1 - one\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SN8gqRGrdBo8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}